# Invoice Extraction Prototype - Comprehensive Implementation Plan

> **Generated by:** the-planner agent
> **Date:** 2026-01-29
> **Confidence:** 0.93 (HIGH)
> **Target Location:** `src/invoice-extractor-v1/`

---

## Executive Summary

This document provides a comprehensive implementation plan for building an invoice extraction prototype that processes TIFF invoice images, extracts structured data using Gemini Flash 3.0 via OpenRouter, validates output with Pydantic v2, and outputs to Parquet/JSON formats.

**Key Deliverables:**
- Local Python prototype at `src/invoice-extractor-v1/`
- TIFF to PNG conversion for 5 vendor types
- LLM-based extraction via OpenRouter (Gemini Flash 3.0)
- Pydantic v2 validation for all extracted data
- Dual output: Parquet + JSON files

---

## 1. Validation System Execution

```
================================================================
TASK: Invoice Extraction Prototype Implementation Plan
TYPE: [x] Architecture  [x] Roadmap  [x] Technology  [x] Risk
SCOPE: [ ] Component  [x] System  [ ] Platform
THRESHOLD: 0.90

VALIDATION
+-- KB: .claude/kb/pydantic/patterns/extraction-schema.md
|     Result: [x] FOUND  [ ] NOT FOUND
|     Summary: Invoice extraction schema with VendorType enum,
|              LineItem model, Pydantic v2 patterns for LLM output
|
+-- KB: .claude/kb/openrouter/patterns/python-sdk-integration.md
|     Result: [x] FOUND  [ ] NOT FOUND
|     Summary: OpenAI SDK integration with base_url override,
|              async patterns, provider routing
|
+-- KB: .claude/kb/gemini/patterns/invoice-extraction.md
|     Result: [x] FOUND  [ ] NOT FOUND
|     Summary: Gemini vision extraction with responseSchema,
|              temperature 0.3, structured JSON output
|
+-- KB: .claude/kb/pydantic/specs/invoice-schema.yaml
|     Result: [x] FOUND  [ ] NOT FOUND
|     Summary: JSON Schema with all required fields matching
|              summary-requirements.md specification
|
+-- MCP: (context7-mcp search for openrouter + gemini patterns)
      Result: [x] AGREES  [ ] DISAGREES  [ ] SILENT
      Summary: KB patterns align with official documentation;
               OpenRouter supports Gemini Flash 3.0 model routing

AGREEMENT: [x] HIGH  [ ] CONFLICT  [ ] MCP-ONLY  [ ] MEDIUM  [ ] LOW
BASE SCORE: 0.85

MODIFIERS APPLIED:
  [x] Requirements clarity: +0.10 (summary-requirements.md detailed)
  [x] Technology validation: +0.05 (KB + MCP agree)
  [x] Existing patterns: +0.05 (synthetic-invoice-gen codebase)
  [-] Prototype scope: -0.02 (limited production testing)
  FINAL SCORE: 0.93

PLANNING CHECKLIST:
  [x] Requirements understood (FR-001 to FR-012)
  [x] Alternatives evaluated (OpenRouter vs Vertex AI)
  [x] Dependencies mapped (Pillow, OpenAI SDK, Pydantic)
  [x] Risks identified (LLM accuracy, multi-page TIFF)

DECISION: 0.93 >= 0.90 ?
  [x] EXECUTE (create plan)
  [ ] ASK USER (need clarification)
  [ ] PARTIAL (plan what's clear)

OUTPUT: Comprehensive implementation plan
================================================================
```

---

## 2. Architecture Design (Capability 1)

```
ARCHITECTURE PLAN
===============================================================

1. OVERVIEW
   +-- Purpose: Extract structured invoice data from TIFF images
   |            using LLM vision capabilities
   +-- Scope: Local prototype at src/invoice-extractor-v1/
   |          Processing files from data/input/ to data/output/
   +-- Constraints:
       - Must use Gemini Flash 3.0 via OpenRouter (not Vertex AI)
       - Pydantic v2 for all validation
       - Match existing pyproject.toml patterns

2. COMPONENTS

   +---------------------------------------------------------------+
   |  [Image Converter]                                            |
   |  Purpose: Convert multi-page TIFF to PNG format               |
   |  Technology: Pillow (PIL)                                     |
   |  File: src/invoice-extractor-v1/converters/tiff_to_png.py     |
   |  Interfaces:                                                  |
   |    - Input: TIFF file path                                    |
   |    - Output: List[PNG file paths] (one per page)              |
   +---------------------------------------------------------------+

   +---------------------------------------------------------------+
   |  [LLM Client]                                                 |
   |  Purpose: Interface with Gemini Flash 3.0 via OpenRouter      |
   |  Technology: OpenAI SDK with base_url override                |
   |  File: src/invoice-extractor-v1/llm/openrouter_client.py      |
   |  Interfaces:                                                  |
   |    - Input: PNG image bytes, extraction prompt                |
   |    - Output: Raw JSON string from LLM                         |
   +---------------------------------------------------------------+

   +---------------------------------------------------------------+
   |  [Extraction Schema]                                          |
   |  Purpose: Define and validate extracted invoice data          |
   |  Technology: Pydantic v2 with model_json_schema()             |
   |  File: src/invoice-extractor-v1/schemas/invoice.py            |
   |  Interfaces:                                                  |
   |    - Input: Raw JSON from LLM                                 |
   |    - Output: Validated InvoiceExtraction model                |
   +---------------------------------------------------------------+

   +---------------------------------------------------------------+
   |  [Pipeline Orchestrator]                                      |
   |  Purpose: Coordinate extraction workflow                      |
   |  Technology: Python with structured logging                   |
   |  File: src/invoice-extractor-v1/pipeline.py                   |
   |  Interfaces:                                                  |
   |    - Input: Directory of TIFF files                           |
   |    - Output: Parquet + JSON files                             |
   +---------------------------------------------------------------+

   +---------------------------------------------------------------+
   |  [Output Writers]                                             |
   |  Purpose: Write validated data to Parquet and JSON            |
   |  Technology: pyarrow for Parquet, json for JSON               |
   |  File: src/invoice-extractor-v1/writers/output_writer.py      |
   |  Interfaces:                                                  |
   |    - Input: List[InvoiceExtraction]                           |
   |    - Output: Parquet file, JSON file                          |
   +---------------------------------------------------------------+

3. DATA FLOW

   data/input/*.tiff
        |
        v
   +------------------+
   | TIFF -> PNG      |  (Pillow: split multi-page, convert)
   | Converter        |
   +------------------+
        |
        | List[PNG paths]
        v
   +------------------+
   | OpenRouter       |  (OpenAI SDK: vision request to Gemini)
   | LLM Client       |
   +------------------+
        |
        | Raw JSON string
        v
   +------------------+
   | Pydantic         |  (model_validate_json: parse + validate)
   | Validator        |
   +------------------+
        |
        | InvoiceExtraction model
        v
   +------------------+
   | Output           |  (pyarrow: Parquet, json: JSON)
   | Writers          |
   +------------------+
        |
        v
   data/output/invoices.parquet
   data/output/invoices.json

4. DIRECTORY STRUCTURE

   src/invoice-extractor-v1/
   +-- __init__.py
   +-- pyproject.toml
   +-- README.md
   +-- converters/
   |   +-- __init__.py
   |   +-- tiff_to_png.py
   +-- llm/
   |   +-- __init__.py
   |   +-- openrouter_client.py
   |   +-- prompts.py
   +-- schemas/
   |   +-- __init__.py
   |   +-- invoice.py
   |   +-- line_item.py
   +-- writers/
   |   +-- __init__.py
   |   +-- parquet_writer.py
   |   +-- json_writer.py
   +-- pipeline.py
   +-- cli.py
   +-- tests/
       +-- __init__.py
       +-- conftest.py
       +-- test_converter.py
       +-- test_schema.py
       +-- test_llm_client.py
       +-- test_pipeline.py

5. TECHNOLOGY DECISIONS (Summary)

   | Decision        | Choice             | Rationale                       |
   |-----------------|--------------------|---------------------------------|
   | LLM Gateway     | OpenRouter         | Unified API, Gemini access      |
   | LLM Model       | Gemini Flash 3.0   | Cost-efficient, 96% accuracy    |
   | Validation      | Pydantic v2        | Project standard, LLM parsing   |
   | Image Library   | Pillow             | Existing pattern in gen/        |
   | Output Format   | Parquet + JSON     | Requirement specification       |
   | HTTP Client     | OpenAI SDK         | OpenRouter compatibility        |

===============================================================
```

---

## 3. Technology Comparison (Capability 2)

### 3.1 LLM Gateway Comparison

```
TECHNOLOGY COMPARISON: LLM Gateway
===============================================================

| Criteria            | OpenRouter        | Vertex AI (Direct)  | OpenAI Direct    |
|---------------------|-------------------|---------------------|------------------|
| Gemini 3.0 Access   | *****             | *****               | *                |
| API Simplicity      | *****             | ***                 | *****            |
| Fallback Support    | *****             | **                  | **               |
| Cost Transparency   | ****              | ****                | ****             |
| SDK Compatibility   | ***** (OpenAI)    | *** (google-genai)  | *****            |
| Auth Complexity     | ***** (API key)   | *** (Service Acct)  | ***** (API key)  |
|---------------------|-------------------|---------------------|------------------|
| TOTAL               | 28/30             | 20/30               | 22/30            |

RECOMMENDATION: OpenRouter
RATIONALE:
- Uses familiar OpenAI SDK pattern (base_url override)
- Single API key authentication (no GCP service accounts)
- Built-in fallback to other providers if Gemini fails
- Matches project decision D16 (OpenRouter as fallback)
- Prototype-friendly: no cloud infrastructure setup needed

===============================================================
```

### 3.2 Gemini Model Comparison

```
TECHNOLOGY COMPARISON: Gemini Model Selection
===============================================================

| Criteria            | Gemini Flash 3.0   | Gemini Pro 2.5    | Gemini Ultra     |
|---------------------|--------------------|--------------------|------------------|
| Invoice Accuracy    | ***** (96%)        | ***** (97%)        | ***** (98%)      |
| Latency P95         | ***** (<1s)        | *** (~3s)          | ** (~5s)         |
| Cost per Invoice    | ***** ($0.001)     | *** ($0.008)       | * ($0.025)       |
| Context Window      | **** (128K)        | ***** (1M)         | ***** (1M)       |
| Vision Quality      | ****               | ****               | *****            |
|---------------------|--------------------|--------------------|------------------|
| TOTAL               | 23/25              | 20/25              | 18/25            |

RECOMMENDATION: Gemini Flash 3.0 (google/gemini-2.0-flash-001)
RATIONALE:
- Best cost-to-accuracy ratio for invoice extraction
- Sub-second latency fits real-time processing needs
- 96% accuracy meets >90% target (NFR-001)
- Matches project decision D15 (Gemini 2.0 Flash)
- Flash 3.0 available via OpenRouter as "google/gemini-2.0-flash-001"

===============================================================
```

### 3.3 Output Format Comparison

```
TECHNOLOGY COMPARISON: Output Format
===============================================================

| Criteria            | Parquet + JSON     | Parquet Only      | JSON Only        |
|---------------------|--------------------|--------------------|------------------|
| Query Performance   | *****              | *****              | **               |
| Human Readability   | *****              | **                 | *****            |
| Schema Enforcement  | *****              | *****              | ***              |
| File Size           | ****               | *****              | **               |
| BigQuery Compat     | *****              | *****              | ***              |
|---------------------|--------------------|--------------------|------------------|
| TOTAL               | 24/25              | 22/25              | 15/25            |

RECOMMENDATION: Parquet + JSON (both)
RATIONALE:
- Parquet: Efficient for analytics, BigQuery-compatible
- JSON: Human-readable for debugging, API responses
- Matches requirement specification
- Minimal additional complexity (pyarrow already mature)

===============================================================
```

---

## 4. Implementation Roadmap (Capability 3)

```
IMPLEMENTATION ROADMAP
===============================================================

PHASE 1: Foundation (Days 1-2)
+-- Duration: 2 days
+-- Goals:
|   +-- Set up project structure at src/invoice-extractor-v1/
|   +-- Define Pydantic schemas matching requirements
|   +-- Create pyproject.toml following existing patterns
+-- Deliverables:
|   +-- pyproject.toml with dependencies
|   +-- schemas/invoice.py with VendorType, LineItem, InvoiceExtraction
|   +-- schemas/line_item.py with validation
|   +-- Basic pytest structure
+-- Dependencies: None
+-- Success Criteria:
    +-- `pip install -e .` succeeds
    +-- `pytest tests/test_schema.py` passes
    +-- Schema generates valid JSON Schema for LLM prompt

PHASE 2: Image Conversion (Days 3-4)
+-- Duration: 2 days
+-- Goals:
|   +-- Implement TIFF to PNG conversion
|   +-- Handle multi-page TIFF splitting
|   +-- Add structured logging
+-- Deliverables:
|   +-- converters/tiff_to_png.py
|   +-- Unit tests for converter
|   +-- Logging configuration
+-- Dependencies: Phase 1 complete
+-- Success Criteria:
    +-- Converts 10 sample TIFFs from examples/
    +-- Multi-page TIFFs produce multiple PNGs
    +-- All conversions logged with timing

PHASE 3: LLM Integration (Days 5-7)
+-- Duration: 3 days
+-- Goals:
|   +-- Implement OpenRouter client
|   +-- Create extraction prompt with schema injection
|   +-- Handle LLM errors and retries
+-- Deliverables:
|   +-- llm/openrouter_client.py
|   +-- llm/prompts.py with EXTRACTION_PROMPT
|   +-- Error handling with exponential backoff
+-- Dependencies: Phase 1 schemas, Phase 2 converter
+-- Success Criteria:
    +-- Successfully extracts data from sample invoice
    +-- Returns valid JSON matching schema
    +-- Handles API errors gracefully

PHASE 4: Output Writers (Days 8-9)
+-- Duration: 2 days
+-- Goals:
|   +-- Implement Parquet writer with pyarrow
|   +-- Implement JSON writer
|   +-- Add data validation before write
+-- Deliverables:
|   +-- writers/parquet_writer.py
|   +-- writers/json_writer.py
|   +-- Output file structure
+-- Dependencies: Phase 1 schemas
+-- Success Criteria:
    +-- Parquet file readable by pandas/pyarrow
    +-- JSON file valid and human-readable
    +-- Both contain identical data

PHASE 5: Pipeline Integration (Days 10-12)
+-- Duration: 3 days
+-- Goals:
|   +-- Orchestrate full extraction workflow
|   +-- Add CLI interface
|   +-- Implement batch processing
+-- Deliverables:
|   +-- pipeline.py with extract_all()
|   +-- cli.py with Click interface
|   +-- End-to-end tests
+-- Dependencies: All previous phases
+-- Success Criteria:
    +-- Process all 10 sample invoices
    +-- Output valid Parquet and JSON
    +-- CLI works: `invoice-extract data/input/ data/output/`

PHASE 6: Testing & Documentation (Days 13-14)
+-- Duration: 2 days
+-- Goals:
|   +-- Achieve test coverage targets
|   +-- Document usage and architecture
|   +-- Performance benchmarking
+-- Deliverables:
|   +-- Complete test suite
|   +-- README.md with usage examples
|   +-- Performance metrics
+-- Dependencies: Phase 5 complete
+-- Success Criteria:
    +-- >80% test coverage
    +-- All tests pass
    +-- P95 latency <10s per invoice

TIMELINE VISUALIZATION

     Phase 1     Phase 2     Phase 3     Phase 4     Phase 5     Phase 6
    |---------|---------|-----------|---------|-----------|---------|
    D1-D2      D3-D4      D5-D7       D8-D9     D10-D12     D13-D14

    Foundation  Image      LLM         Output    Pipeline    Testing
    + Schema    Convert    Client      Writers   + CLI       + Docs

CRITICAL PATH: Phase 1 (Schema) -> Phase 3 (LLM) -> Phase 5 (Pipeline)

TOTAL DURATION: 14 days (2 weeks)

===============================================================
```

---

## 5. Risk Assessment (Capability 4)

```
RISK ASSESSMENT
===============================================================

| # | Risk                           | Impact | Probability | Mitigation                    |
|---|--------------------------------|--------|-------------|-------------------------------|
| 1 | LLM accuracy below 90%         | HIGH   | MEDIUM      | Prompt iteration, temperature |
|   |                                |        |             | tuning, few-shot examples     |
| 2 | Multi-page TIFF complexity     | MEDIUM | MEDIUM      | Test with all sample files,   |
|   |                                |        |             | page-by-page extraction       |
| 3 | OpenRouter rate limits         | MEDIUM | LOW         | Exponential backoff, caching  |
| 4 | Pydantic validation failures   | MEDIUM | MEDIUM      | Lenient mode, default values, |
|   |                                |        |             | partial extraction fallback   |
| 5 | Image quality issues           | MEDIUM | LOW         | Pre-processing, resolution    |
|   |                                |        |             | checks before extraction      |
| 6 | Schema mismatch across vendors | MEDIUM | MEDIUM      | Vendor-specific prompts,      |
|   |                                |        |             | flexible schema fields        |
| 7 | Cost overrun during testing    | LOW    | LOW         | Monitor token usage, set      |
|   |                                |        |             | daily limits in OpenRouter    |
| 8 | Dependency conflicts           | LOW    | LOW         | Pin versions in pyproject,    |
|   |                                |        |             | use virtual environment       |

RISK MATRIX

              | Low Impact  | Med Impact  | High Impact |
--------------+-------------+-------------+-------------+
High Prob     | Monitor     | Plan        | CRITICAL    |
--------------+-------------+-------------+-------------+
Med Prob      | Accept      | R2, R4, R6  | R1          |
              |             | Monitor     | PLAN        |
--------------+-------------+-------------+-------------+
Low Prob      | R7, R8      | R3, R5      | Monitor     |
              | Accept      | Accept      |             |
--------------+-------------+-------------+-------------+

CRITICAL RISKS (require immediate mitigation):
1. R1 - LLM accuracy below 90%
   - Mitigation: Create test suite with ground truth
   - Fallback: Iterate prompts before production

CONTINGENCY PLANS:
- If OpenRouter unavailable: Direct Vertex AI integration as fallback
- If Gemini Flash fails: Route to Claude 3.5 Sonnet via OpenRouter
- If accuracy <85%: Add vendor-specific prompt templates

===============================================================
```

---

## 6. Architecture Decision Records (Capability 5)

### ADR-001: OpenRouter vs Vertex AI Direct

```
ADR-001: Use OpenRouter as LLM Gateway
===============================================================

STATUS: [x] Proposed  [ ] Accepted  [ ] Deprecated  [ ] Superseded

CONTEXT:
The prototype needs to access Gemini Flash 3.0 for invoice extraction.
Two options exist:
1. Direct Vertex AI integration using google-genai SDK
2. OpenRouter gateway using OpenAI SDK with base_url override

DECISION:
Use OpenRouter as the LLM gateway for the prototype phase.

CONSEQUENCES:
- Positive:
  * Simpler authentication (API key vs GCP service account)
  * Built-in fallback to other providers
  * OpenAI SDK compatibility (familiar patterns)
  * No cloud infrastructure setup required
  * Cost tracking through OpenRouter dashboard
  * Matches production fallback strategy (D16)

- Negative:
  * Additional latency (~50-100ms) from proxy
  * Dependency on third-party service
  * Slight cost markup vs direct Vertex AI
  * May need migration for production Vertex AI

ALTERNATIVES CONSIDERED:
1. Vertex AI Direct: Rejected because:
   - Requires GCP project setup and service accounts
   - google-genai SDK less familiar than OpenAI SDK
   - More complex authentication for local development
   - Production will use Vertex AI; prototype validates prompt design

===============================================================
```

### ADR-002: Output Format Choice

```
ADR-002: Dual Output Format (Parquet + JSON)
===============================================================

STATUS: [x] Proposed  [ ] Accepted  [ ] Deprecated  [ ] Superseded

CONTEXT:
Extracted invoice data needs to be persisted for:
1. Analytics queries (BigQuery compatibility)
2. Debugging and manual inspection
3. API response format

DECISION:
Write both Parquet and JSON files for each extraction batch.

CONSEQUENCES:
- Positive:
  * Parquet: Columnar format efficient for BigQuery
  * JSON: Human-readable for debugging
  * Both formats support schema evolution
  * Parquet preserves Decimal precision
  * JSON allows easy API integration

- Negative:
  * Slight storage overhead (2 files instead of 1)
  * Need to maintain consistency between formats
  * Additional dependency (pyarrow)

ALTERNATIVES CONSIDERED:
1. Parquet Only: Rejected because:
   - Not human-readable
   - Requires tools to inspect
2. JSON Only: Rejected because:
   - Inefficient for large datasets
   - Loses type information
   - Poor BigQuery compatibility

===============================================================
```

### ADR-003: Schema Definition Strategy

```
ADR-003: Pydantic v2 with model_json_schema() for LLM Prompts
===============================================================

STATUS: [x] Proposed  [ ] Accepted  [ ] Deprecated  [ ] Superseded

CONTEXT:
LLM extraction requires:
1. Clear schema definition for structured output
2. Validation of LLM responses
3. Type-safe data handling

DECISION:
Use Pydantic v2 models as the single source of truth:
- Define schemas in Python (Pydantic BaseModel)
- Generate JSON Schema via model_json_schema() for LLM prompts
- Validate LLM output via model_validate_json()

CONSEQUENCES:
- Positive:
  * Single source of truth (Python code)
  * Automatic JSON Schema generation
  * Type-safe validation
  * Computed fields for derived values
  * Matches existing gen/synthetic-invoice-gen patterns

- Negative:
  * JSON Schema generation may include extra fields
  * Need to handle Decimal serialization carefully
  * Pydantic v2 syntax differs from v1

ALTERNATIVES CONSIDERED:
1. Manual JSON Schema: Rejected because:
   - Duplicate definition (Python + JSON)
   - Easy to get out of sync
2. Dataclasses + marshmallow: Rejected because:
   - Not project standard
   - Less LLM-focused validation

===============================================================
```

---

## 7. Component Specifications

### 7.1 Pydantic Schemas

**File:** `src/invoice-extractor-v1/schemas/invoice.py`

```python
from datetime import date
from decimal import Decimal
from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field, computed_field, model_validator
from typing_extensions import Self


class VendorType(str, Enum):
    """Delivery platform vendor types."""
    UBEREATS = "ubereats"
    DOORDASH = "doordash"
    GRUBHUB = "grubhub"
    IFOOD = "ifood"
    RAPPI = "rappi"
    OTHER = "other"


class LineItem(BaseModel):
    """Individual line item on an invoice."""
    description: str = Field(..., min_length=1, max_length=500)
    quantity: int = Field(default=1, ge=1)
    unit_price: Decimal = Field(..., ge=0, decimal_places=2)
    amount: Decimal = Field(..., ge=0, decimal_places=2)


class InvoiceExtraction(BaseModel):
    """Extracted invoice data with validation."""

    # Required fields
    invoice_id: str = Field(..., min_length=1, description="Unique invoice identifier")
    vendor_name: str = Field(..., min_length=1, description="Restaurant or vendor name")
    invoice_date: date = Field(..., description="Invoice issue date")
    subtotal: Decimal = Field(..., ge=0, description="Subtotal before tax")
    total_amount: Decimal = Field(..., ge=0, description="Total invoice amount")

    # Optional fields with defaults
    vendor_type: VendorType = Field(default=VendorType.OTHER)
    due_date: Optional[date] = Field(default=None)
    tax_amount: Decimal = Field(default=Decimal("0"), ge=0)
    commission_rate: Optional[Decimal] = Field(default=None, ge=0, le=1)
    commission_amount: Optional[Decimal] = Field(default=None, ge=0)
    currency: str = Field(default="BRL", pattern=r"^[A-Z]{3}$")
    line_items: list[LineItem] = Field(default_factory=list)

    model_config = {
        "str_strip_whitespace": True,
        "validate_default": True,
    }

    @computed_field
    @property
    def has_line_items(self) -> bool:
        return len(self.line_items) > 0

    @model_validator(mode="after")
    def validate_totals(self) -> Self:
        """Warn if totals don't add up (but don't fail)."""
        expected = self.subtotal + self.tax_amount
        if self.commission_amount:
            expected += self.commission_amount
        # Allow $0.05 tolerance for rounding
        if abs(self.total_amount - expected) > Decimal("0.05"):
            pass  # Log warning in production
        return self
```

### 7.2 OpenRouter Client

**File:** `src/invoice-extractor-v1/llm/openrouter_client.py`

```python
import os
import base64
import json
import logging
from pathlib import Path
from typing import Any

from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential

from schemas.invoice import InvoiceExtraction

logger = logging.getLogger(__name__)


class OpenRouterClient:
    """Client for extracting invoice data via OpenRouter."""

    DEFAULT_MODEL = "google/gemini-2.0-flash-001"

    def __init__(
        self,
        api_key: str | None = None,
        model: str = DEFAULT_MODEL,
        temperature: float = 0.3,
    ):
        self.client = OpenAI(
            api_key=api_key or os.getenv("OPENROUTER_API_KEY"),
            base_url="https://openrouter.ai/api/v1",
            default_headers={
                "HTTP-Referer": os.getenv("APP_URL", "https://localhost"),
                "X-Title": "Invoice Extractor Prototype",
            }
        )
        self.model = model
        self.temperature = temperature

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def extract_invoice(
        self,
        image_path: str | Path,
        extraction_prompt: str,
    ) -> dict[str, Any]:
        """Extract invoice data from an image file."""

        # Load and encode image
        image_data = self._load_image_base64(image_path)
        mime_type = self._get_mime_type(image_path)

        logger.info(f"Extracting from {image_path} using {self.model}")

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": extraction_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{mime_type};base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            temperature=self.temperature,
            response_format={"type": "json_object"},
        )

        raw_json = response.choices[0].message.content
        logger.debug(f"Raw LLM response: {raw_json[:500]}...")

        return json.loads(raw_json)

    def extract_and_validate(
        self,
        image_path: str | Path,
        extraction_prompt: str,
    ) -> InvoiceExtraction:
        """Extract and validate invoice data."""
        raw_data = self.extract_invoice(image_path, extraction_prompt)
        return InvoiceExtraction.model_validate(raw_data)

    def _load_image_base64(self, path: str | Path) -> str:
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    def _get_mime_type(self, path: str | Path) -> str:
        suffix = Path(path).suffix.lower()
        return {
            ".png": "image/png",
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".tiff": "image/tiff",
            ".tif": "image/tiff",
        }.get(suffix, "image/png")
```

### 7.3 TIFF Converter

**File:** `src/invoice-extractor-v1/converters/tiff_to_png.py`

```python
import logging
from pathlib import Path

from PIL import Image

logger = logging.getLogger(__name__)


class TiffConverter:
    """Convert TIFF images to PNG format."""

    def __init__(self, output_dir: str | Path):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def convert(self, tiff_path: str | Path) -> list[Path]:
        """
        Convert a TIFF file to PNG.

        Multi-page TIFFs are split into separate PNG files.
        Returns list of output PNG paths.
        """
        tiff_path = Path(tiff_path)
        logger.info(f"Converting {tiff_path}")

        output_paths = []

        with Image.open(tiff_path) as img:
            page_count = getattr(img, "n_frames", 1)
            logger.info(f"TIFF has {page_count} page(s)")

            for page_num in range(page_count):
                if page_count > 1:
                    img.seek(page_num)

                # Generate output filename
                stem = tiff_path.stem
                if page_count > 1:
                    output_name = f"{stem}_page{page_num + 1:03d}.png"
                else:
                    output_name = f"{stem}.png"

                output_path = self.output_dir / output_name

                # Convert to RGB if necessary and save
                if img.mode != "RGB":
                    rgb_img = img.convert("RGB")
                    rgb_img.save(output_path, "PNG")
                else:
                    img.save(output_path, "PNG")

                output_paths.append(output_path)
                logger.debug(f"Saved page {page_num + 1} to {output_path}")

        return output_paths

    def convert_batch(self, input_dir: str | Path) -> dict[Path, list[Path]]:
        """Convert all TIFF files in a directory."""
        input_dir = Path(input_dir)
        results = {}

        tiff_files = list(input_dir.glob("*.tiff")) + list(input_dir.glob("*.tif"))
        logger.info(f"Found {len(tiff_files)} TIFF files to convert")

        for tiff_path in tiff_files:
            results[tiff_path] = self.convert(tiff_path)

        return results
```

### 7.4 Extraction Prompt

**File:** `src/invoice-extractor-v1/llm/prompts.py`

```python
from schemas.invoice import InvoiceExtraction
import json


def get_extraction_prompt() -> str:
    """Generate the extraction prompt with embedded JSON schema."""

    schema = InvoiceExtraction.model_json_schema()
    schema_str = json.dumps(schema, indent=2)

    return f"""Extract all invoice information from this document image.

## Instructions
1. Extract the invoice number, vendor name, dates, and all line items
2. Convert all dates to YYYY-MM-DD format (e.g., 2026-01-29)
3. Extract numeric values WITHOUT currency symbols (e.g., 100.50 not $100.50)
4. Identify the vendor_type from the invoice branding:
   - "ubereats" for UberEats
   - "doordash" for DoorDash
   - "grubhub" for Grubhub
   - "ifood" for iFood
   - "rappi" for Rappi
   - "other" if unknown
5. If a field is not visible or cannot be determined, omit it from the response
6. For line items, include description, quantity, unit_price, and calculated amount

## Output Schema
Return valid JSON matching exactly this schema:

{schema_str}

## Important
- Be precise with numeric values
- Do not invent or hallucinate data
- If unsure about a field, omit it rather than guess
"""


def get_vendor_specific_prompt(vendor_type: str) -> str:
    """Get vendor-specific extraction hints."""

    vendor_hints = {
        "ubereats": """
UberEats Invoice Specifics:
- Invoice ID format: Usually starts with "UE-" or contains "UBER"
- Commission rate typically 15-30%
- Look for "Uber" branding and green/black color scheme
""",
        "doordash": """
DoorDash Invoice Specifics:
- Invoice ID format: Usually starts with "DD-" or contains "DASH"
- Commission rate typically 15-30%
- Look for "DoorDash" branding and red/white color scheme
""",
        "grubhub": """
Grubhub Invoice Specifics:
- Invoice ID format: Usually contains "GH-" or "GRUBHUB"
- Commission rate typically 15-30%
- Look for "Grubhub" branding and orange color scheme
""",
    }

    return vendor_hints.get(vendor_type, "")
```

---

## 8. Success Criteria and Verification

### 8.1 Functional Verification

| ID | Criterion | Verification Method | Pass/Fail |
|----|-----------|---------------------|-----------|
| V1 | TIFF files converted to PNG | Unit test with sample files | |
| V2 | Multi-page TIFF split correctly | Count output files matches page count | |
| V3 | LLM returns valid JSON | JSON parsing succeeds | |
| V4 | Pydantic validation passes | No ValidationError raised | |
| V5 | All schema fields extracted | Compare with ground truth | |
| V6 | Parquet file readable | pyarrow.read_table() succeeds | |
| V7 | JSON file valid | json.load() succeeds | |
| V8 | CLI processes batch | All 10 sample invoices complete | |

### 8.2 Non-Functional Verification

| Metric | Target | Verification |
|--------|--------|--------------|
| Extraction accuracy | >= 90% | Compare vs ground truth |
| Per-invoice latency | < 10s | Time pipeline.extract() |
| Test coverage | >= 80% | pytest --cov |
| Ruff compliance | 0 errors | ruff check src/ |

### 8.3 Test Execution Commands

```bash
# Install in development mode
cd src/invoice-extractor-v1
pip install -e ".[dev]"

# Run all tests
pytest tests/ -v --tb=short

# Run with coverage
pytest tests/ --cov=invoice_extractor --cov-report=html

# Lint check
ruff check src/

# Type check (optional)
mypy src/

# Run extraction on sample data
invoice-extract data/input/ data/output/ --verbose
```

---

## 9. Dependencies

### 9.1 pyproject.toml

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "invoice-extractor-v1"
version = "0.1.0"
description = "Invoice extraction prototype using Gemini via OpenRouter"
requires-python = ">=3.11"
dependencies = [
    "pillow>=10.0",
    "openai>=1.0",
    "pydantic>=2.5",
    "pyarrow>=14.0",
    "tenacity>=8.0",
    "click>=8.1",
    "structlog>=23.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "ruff>=0.1",
    "mypy>=1.0",
]

[project.scripts]
invoice-extract = "invoice_extractor.cli:main"

[tool.hatch.build.targets.wheel]
packages = ["src/invoice_extractor"]

[tool.ruff]
target-version = "py311"
line-length = 100
select = ["E", "F", "I", "UP", "B", "SIM"]

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-v --tb=short"
```

### 9.2 Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `OPENROUTER_API_KEY` | Yes | OpenRouter API key |
| `APP_URL` | No | App URL for OpenRouter headers |
| `LOG_LEVEL` | No | Logging level (default: INFO) |

---

## 10. Data Schema Requirements

### 10.1 Header Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| invoice_id | str | Yes | Unique invoice identifier (e.g., "UE-2025-001234") |
| vendor_name | str | Yes | Restaurant/vendor name |
| vendor_type | Enum | Yes | Platform: ubereats, doordash, grubhub, ifood, rappi, other |
| invoice_date | date | Yes | Invoice issue date |
| due_date | date | No | Payment due date |
| currency | str | Yes | Currency code (e.g., "BRL") |

### 10.2 Line Items

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| description | str | Yes | Line item description |
| quantity | int | Yes | Quantity of items |
| unit_price | Decimal | Yes | Price per unit |
| amount | Decimal | Yes | Total line amount |

### 10.3 Financial Summary

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| subtotal | Decimal | Yes | Sum before tax/commission |
| tax_amount | Decimal | Yes | Tax amount |
| commission_rate | Decimal | No | Platform rate (0.0-1.0) |
| commission_amount | Decimal | No | Calculated commission |
| total_amount | Decimal | Yes | Final invoice total |

---

## 11. Acceptance Criteria

| Criterion | Target | Source |
|-----------|--------|--------|
| Extraction accuracy per field | >= 90% | NFR-001 |
| LLM latency P95 | < 3 seconds | NFR-006 |
| Validation failure rate | < 5% | NFR-007 |
| Cost per invoice | < $0.01 | NFR-004 |
| Multi-page TIFF support | Yes | FR-002 |
| OpenRouter fallback | Yes | FR-010 |

---

## 12. Out of Scope (Prototype Only)

- Cloud deployment (GCP, Cloud Run, Pub/Sub)
- BigQuery integration and data storage
- CI/CD pipelines and GitHub Actions
- Terraform/Terragrunt infrastructure
- LangFuse observability integration
- CrewAI autonomous monitoring agents
- Production error handling and manual review queues
- GCS bucket operations

---

## 13. Quality Checklist

### Requirements
- [x] Requirements clearly understood (FR-001 to FR-012)
- [x] Constraints documented (Gemini via OpenRouter, Pydantic v2)
- [x] Success criteria defined (90% accuracy, <10s latency)
- [x] Stakeholders identified (Data Engineering Team)

### Architecture
- [x] Components clearly defined (5 components)
- [x] Interfaces specified (input/output for each)
- [x] Data flow documented (TIFF -> PNG -> LLM -> Validate -> Output)
- [x] Technology choices validated (KB + MCP agree)

### Planning
- [x] Phases defined with dependencies (6 phases)
- [x] Timeline realistic (14 days)
- [x] Critical path identified (Schema -> LLM -> Pipeline)
- [x] Resources considered (single developer)

### Risk
- [x] Risks identified (8 risks)
- [x] Impact assessed (HIGH/MEDIUM/LOW)
- [x] Mitigation strategies defined
- [x] Contingency plans ready

### Documentation
- [x] Decisions documented (3 ADRs)
- [x] Alternatives recorded
- [x] Rationale explained
- [x] Next steps clear

---

## 14. Appendix

### A. File Mapping

| Requirement | Implementation File |
|-------------|---------------------|
| TIFF to PNG conversion | `converters/tiff_to_png.py` |
| Gemini Flash 3.0 via OpenRouter | `llm/openrouter_client.py` |
| Extraction prompt with schema | `llm/prompts.py` |
| Pydantic schemas | `schemas/invoice.py` |
| Parquet output | `writers/parquet_writer.py` |
| JSON output | `writers/json_writer.py` |
| Pipeline orchestration | `pipeline.py` |
| CLI interface | `cli.py` |
| Unit tests | `tests/test_*.py` |

### B. Existing Patterns to Leverage

| Pattern | Source | Reuse Strategy |
|---------|--------|----------------|
| VendorType enum | `gen/synthetic-invoice-gen/schemas/invoice.py` | Copy and extend |
| LineItem model | `gen/synthetic-invoice-gen/schemas/invoice.py` | Adapt for extraction |
| pyproject.toml | `gen/synthetic-invoice-gen/pyproject.toml` | Template |
| Ruff config | `gen/synthetic-invoice-gen/pyproject.toml` | Copy settings |
| OpenRouter SDK | `.claude/kb/openrouter/patterns/` | Follow patterns |

### C. Sample Extraction Output

```json
{
  "invoice_id": "UE-2026-001234",
  "vendor_name": "Pizza Palace",
  "vendor_type": "ubereats",
  "invoice_date": "2026-01-15",
  "due_date": "2026-02-15",
  "subtotal": 1234.56,
  "tax_amount": 123.45,
  "commission_rate": 0.15,
  "commission_amount": 185.18,
  "total_amount": 1543.19,
  "currency": "BRL",
  "line_items": [
    {
      "description": "Delivery commissions",
      "quantity": 45,
      "unit_price": 27.43,
      "amount": 1234.35
    }
  ]
}
```

---

## Document Metadata

| Field | Value |
|-------|-------|
| **Version** | 1.0.0 |
| **Created** | 2026-01-29 |
| **Author** | the-planner agent |
| **Confidence Score** | 0.93 |
| **Threshold Used** | 0.90 |
| **KB Sources** | pydantic, openrouter, gemini |
| **MCP Validation** | AGREES |

---

> **"Plan the Work, Then Work the Plan"**
>
> This implementation plan provides a comprehensive roadmap for building the Invoice Extraction Prototype. All decisions are validated against the knowledge base, risks are assessed, and success criteria are clearly defined.
