# PROMPT: INVOICE_EXTRACTOR

> **Auto-generated by:** prompt-crafter
> **Target:** src/invoice-extractor
> **Quality Tier:** production
> **Status:** READY

---

## META

| Field | Value |
|-------|-------|
| **Name** | invoice-extractor |
| **Target Directory** | src/invoice-extractor |
| **Design Document** | design/invoice-extractor-design.md |
| **Requirements** | design/invoice-extractor-requirements.md |
| **Priority** | P0-Critical |
| **Quality Tier** | production |

---

## GOAL

Build a production-ready invoice data extraction system that processes TIFF/PDF files from data/input/, extracts structured invoice data using LLM (Gemini 2.0 Flash with OpenRouter fallback), validates output against Pydantic schemas, and writes Parquet results to data/output/ with an archive copy to data/store/.

**Definition of Done:** CLI command `extract` successfully processes sample invoices with >= 90% field accuracy, writes Parquet output, passes pytest tests, and includes complete verification.

---

## CONTEXT

### Design Overview

This system implements a 5-stage pipeline:
1. **Image Processor** - Convert TIFF/PDF to PNG
2. **Vendor Classifier** - Detect vendor type (ubereats/doordash/grubhub/other)
3. **Prompt Manager** - Load vendor-specific extraction prompts
4. **LLM Gateway** - Extract data via Gemini (primary) or OpenRouter (fallback)
5. **Validator** - Three-layer validation (JSON, Schema, Business Rules)

### Key Constraints

- **Target Directory:** `src/invoice-extractor` (NOT `invoice-extractor/`)
- **Output Format:** Parquet (NOT JSON per original design)
- **Data Paths:**
  - Input: `data/input/` (TIFF/PDF files)
  - Output: `data/output/` (Parquet results)
  - Archive: `data/store/` (processed files)
- **Schema:** 12 fields via Pydantic InvoiceData model
- **LLM Stack:** Gemini 2.0 Flash (Vertex AI) â†’ OpenRouter (Claude/GPT-4o) fallback
- **Verification:** Exit-code based commands, pytest tests

### Acceptance Criteria

| Metric | Target | Verification |
|--------|--------|--------------|
| Field extraction accuracy | >= 90% | Manual validation on sample set |
| Validation pass rate | >= 95% | Pydantic validation logs |
| Processing time P95 | < 30 seconds | Metadata tracking |
| Cost per invoice | < $0.01 | Cost tracking in metadata |

---

## TASKS (Prioritized)

### ðŸ”´ RISKY (Do First)

These tasks involve architectural decisions, external dependencies, and unknowns.

- [ ] **Task 1.1:** Validate GCP/OpenRouter credentials and API access
  - **Agent:** Manual (User verification)
  - **Description:** Ensure GCP_PROJECT_ID, OPENROUTER_API_KEY are set and valid. Test Vertex AI and OpenRouter connectivity.
  - **Acceptance:** Both APIs return 200 on test call
  - **Verify:** `python -c "from google.cloud import aiplatform; print('GCP OK')" && echo "OpenRouter test needed"`

- [ ] **Task 1.2:** Design Parquet output schema and file naming convention
  - **Agent:** @python-developer
  - **Description:** Define Parquet schema matching InvoiceData, decide on partitioning strategy, and file naming (e.g., `{vendor_type}/{invoice_id}_{timestamp}.parquet`)
  - **Acceptance:** Parquet schema document created in `src/invoice-extractor/docs/parquet_schema.md`
  - **Verify:** `test -f src/invoice-extractor/docs/parquet_schema.md`

- [ ] **Task 1.3:** Implement image quality assessment algorithm
  - **Agent:** @python-developer
  - **Description:** Create blur detection, resolution check, and contrast assessment for image quality scoring (0.0-1.0)
  - **Acceptance:** Quality scorer returns consistent scores for good/bad test images
  - **Verify:** `pytest tests/unit/test_image_quality.py -v`

### ðŸŸ¡ CORE (Main Implementation)

- [ ] **Task 2.1:** Create project structure and setup files
  - **Agent:** @python-developer
  - **Description:** Initialize `src/invoice-extractor/` with all directories, `__init__.py`, `pyproject.toml`, `requirements.txt`, `.env.example`
  - **Acceptance:** All directories exist, imports work
  - **Verify:** `python -c "from src.invoice_extractor import extractor; print('OK')"`

- [ ] **Task 2.2:** Implement Pydantic schemas (InvoiceData, LineItem, ExtractionResult)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/schema.py` with full validation, field validators, model validators per design doc Section 3.1-3.2
  - **Acceptance:** Schema validates sample JSON, handles edge cases
  - **Verify:** `pytest tests/unit/test_schema.py -v`

- [ ] **Task 2.3:** Implement configuration system (config.py + YAML loader)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/config.py` with Pydantic config models, YAML loading, env var substitution per design Section 3.3
  - **Acceptance:** Loads `config/config.yaml` with env var expansion
  - **Verify:** `python -c "from src.invoice_extractor.config import load_config; load_config('config/config.yaml')"`

- [ ] **Task 2.4:** Implement ImageProcessor (TIFF/PDF to PNG conversion)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/image/processor.py` with TIFF/PDF handling, multi-page split, quality check per design Section 2.1
  - **Acceptance:** Converts sample TIFF to PNG list
  - **Verify:** `pytest tests/unit/test_image_processor.py -v`

- [ ] **Task 2.5:** Implement PromptManager (vendor-specific templates)
  - **Agent:** @ai-prompt-specialist + @python-developer
  - **Description:** Create prompt templates in `src/invoice-extractor/prompts/templates/` (ubereats.txt, doordash.txt, grubhub.txt, generic.txt, classification.txt) and manager logic per design Section 2.4
  - **Acceptance:** Returns correct prompt for each vendor type
  - **Verify:** `pytest tests/unit/test_prompt_manager.py -v`

- [ ] **Task 2.6:** Implement LLM Gateway with Gemini + OpenRouter adapters
  - **Agent:** @llm-specialist + @python-developer
  - **Description:** Create `src/invoice-extractor/llm/gateway.py`, `gemini.py`, `openrouter.py` with automatic fallback, retry logic, cost tracking per design Section 2.2
  - **Acceptance:** Successfully calls Gemini, falls back to OpenRouter on failure
  - **Verify:** `pytest tests/integration/test_llm_gateway.py -v`

- [ ] **Task 2.7:** Implement three-layer Validator
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/validation/validator.py` and layers (input_validation.py, schema_validation.py, business_validation.py) per design Section 4
  - **Acceptance:** Validates JSON â†’ Pydantic â†’ Business rules
  - **Verify:** `pytest tests/unit/test_validator.py -v`

- [ ] **Task 2.8:** Implement ResultAggregator (response envelope builder)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/aggregator.py` to assemble ExtractionResult with metadata per design Section 2.5
  - **Acceptance:** Builds complete response with metadata
  - **Verify:** `pytest tests/unit/test_aggregator.py -v`

- [ ] **Task 2.9:** Implement main Extractor orchestrator
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/extractor.py` to orchestrate full pipeline: ImageProcessor â†’ Classifier â†’ PromptManager â†’ LLMGateway â†’ Validator â†’ Aggregator
  - **Acceptance:** End-to-end extraction on sample TIFF succeeds
  - **Verify:** `pytest tests/integration/test_extractor.py -v`

- [ ] **Task 2.10:** Implement Parquet writer (output to data/output/)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/output/parquet_writer.py` to convert ExtractionResult to Parquet and write to data/output/ with partitioning
  - **Acceptance:** Writes valid Parquet file from sample extraction
  - **Verify:** `python -c "import pyarrow.parquet as pq; df=pq.read_table('data/output/test.parquet'); print(df.shape)"`

- [ ] **Task 2.11:** Implement file archiver (copy to data/store/)
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/output/archiver.py` to copy processed files to data/store/ with metadata
  - **Acceptance:** Archives sample file with correct naming
  - **Verify:** `test -f data/store/ubereats/archived_file.tiff`

- [ ] **Task 2.12:** Build CLI with `extract` command
  - **Agent:** @python-developer
  - **Description:** Create `src/invoice-extractor/cli.py` using Click or Typer with `extract` command (single file, batch, watch mode)
  - **Acceptance:** `python -m src.invoice_extractor.cli extract data/input/sample.tiff` works
  - **Verify:** `python -m src.invoice_extractor.cli extract --help`

- [ ] **Task 2.13:** Create test fixtures and sample data
  - **Agent:** @test-generator
  - **Description:** Create test fixtures in `tests/fixtures/` (sample invoices, mock LLM responses, expected outputs) per design Section 5.2
  - **Acceptance:** Fixtures cover all vendors and edge cases
  - **Verify:** `ls tests/fixtures/invoices/*.tiff | wc -l` (>= 3)

- [ ] **Task 2.14:** Write comprehensive unit tests
  - **Agent:** @test-generator
  - **Description:** Create unit tests for all modules with >= 80% coverage per design Phase 3A
  - **Acceptance:** All unit tests pass
  - **Verify:** `pytest tests/unit/ -v --cov=src.invoice_extractor --cov-report=term-missing`

- [ ] **Task 2.15:** Write integration tests (mocked + live)
  - **Agent:** @test-generator
  - **Description:** Create integration tests for full pipeline with mocked LLM and optional live tests per design Phase 3B
  - **Acceptance:** Integration tests pass with mocks
  - **Verify:** `pytest tests/integration/ -v -m "not live"`

### ðŸŸ¢ POLISH (Do Last)

- [ ] **Task 3.1:** Add structured logging with JSON output
  - **Agent:** @python-developer
  - **Description:** Implement JSON logging throughout pipeline with correlation IDs, latency tracking, cost logging
  - **Acceptance:** Logs are parseable JSON with all metadata
  - **Verify:** `grep -q '"model_used"' logs/extractor.log`

- [ ] **Task 3.2:** Create comprehensive README.md
  - **Agent:** @code-documenter
  - **Description:** Write README with setup instructions, usage examples, architecture diagram, troubleshooting
  - **Acceptance:** README covers all sections
  - **Verify:** `test -f src/invoice-extractor/README.md`

- [ ] **Task 3.3:** Add type checking with mypy
  - **Agent:** @python-developer
  - **Description:** Configure mypy, add type stubs, ensure all code passes type checking
  - **Acceptance:** `mypy src/invoice-extractor/` passes
  - **Verify:** `mypy src/invoice-extractor/ --strict`

- [ ] **Task 3.4:** Add code formatting and linting (ruff/black)
  - **Agent:** @code-reviewer
  - **Description:** Configure ruff/black, format all code, add pre-commit hooks
  - **Acceptance:** Code passes linting
  - **Verify:** `ruff check src/invoice-extractor/ && black --check src/invoice-extractor/`

- [ ] **Task 3.5:** Performance profiling and optimization
  - **Agent:** @python-developer
  - **Description:** Profile extraction pipeline, identify bottlenecks, optimize where P95 > 30s
  - **Acceptance:** P95 latency < 30 seconds on sample set
  - **Verify:** `python scripts/benchmark.py`

- [ ] **Task 3.6:** Create end-to-end smoke test script
  - **Agent:** @test-generator
  - **Description:** Create `scripts/smoke_test.sh` that processes all sample invoices and validates output
  - **Acceptance:** Smoke test passes on all samples
  - **Verify:** `bash scripts/smoke_test.sh`

---

## EXIT CRITERIA

These are objective, command-based checks that define completion.

| # | Criterion | Verification Command | Status |
|---|-----------|---------------------|--------|
| 1 | All dependencies install cleanly | `pip install -r src/invoice-extractor/requirements.txt` | â¬œ |
| 2 | Project imports without errors | `python -c "from src.invoice_extractor import extractor"` | â¬œ |
| 3 | Schema validation passes | `pytest tests/unit/test_schema.py -v` | â¬œ |
| 4 | Image processing works | `pytest tests/unit/test_image_processor.py -v` | â¬œ |
| 5 | LLM gateway with fallback works | `pytest tests/integration/test_llm_gateway.py -v` | â¬œ |
| 6 | Three-layer validation passes | `pytest tests/unit/test_validator.py -v` | â¬œ |
| 7 | End-to-end extraction works | `pytest tests/integration/test_extractor.py -v` | â¬œ |
| 8 | Parquet output is valid | `python -c "import pyarrow.parquet as pq; pq.read_table('data/output/test.parquet')"` | â¬œ |
| 9 | CLI command works | `python -m src.invoice_extractor.cli extract data/input/ubereats_INV-UE-19561B_20260123.tiff --dry-run` | â¬œ |
| 10 | All unit tests pass | `pytest tests/unit/ -v` | â¬œ |
| 11 | All integration tests pass | `pytest tests/integration/ -v -m "not live"` | â¬œ |
| 12 | Code passes type checking | `mypy src/invoice-extractor/ --strict` | â¬œ |
| 13 | Code passes linting | `ruff check src/invoice-extractor/` | â¬œ |
| 14 | Smoke test passes | `bash scripts/smoke_test.sh` | â¬œ |
| 15 | Sample files extracted >= 90% accuracy | Manual validation with ground truth | â¬œ |

---

## SAFEGUARDS

| Safeguard | Value | Enforcement |
|-----------|-------|-------------|
| `max_iterations` | 40 | Stop after 40 dev loop iterations |
| `max_retries` | 3 | Retry failed verifications 3 times |
| `circuit_breaker` | 3 | Stop if no progress for 3 consecutive loops |
| `small_steps` | true | One logical change per task |
| `hitl_mode` | true | Pause for human review after RISKY tasks |

---

## PROGRESS

**Status:** NOT_STARTED
**Tasks Completed:** 0 / 27
**Last Updated:** 2026-01-29

---

## CONFIG

```yaml
mode: hitl
quality_tier: production
max_iterations: 40
max_retries: 3
circuit_breaker: 3
small_steps: true
feedback_loops:
  - pytest tests/unit/ -v --tb=short
  - ruff check src/invoice-extractor/
```

---

## NOTES

### Design References

- **Design Document:** design/invoice-extractor-design.md
- **Requirements:** design/invoice-extractor-requirements.md
- **Architecture:** 5-stage pipeline (Image â†’ Classifier â†’ Prompt â†’ LLM â†’ Validator)
- **LLM Stack:** Gemini 2.0 Flash (primary) â†’ OpenRouter (fallback)
- **Validation:** 3-layer (JSON parse â†’ Pydantic schema â†’ Business rules)

### Key Decisions

1. **Parquet Output:** Changed from JSON to Parquet per user requirement for better data pipeline integration
2. **Data Paths:** Following user-specified paths (data/input/, data/output/, data/store/)
3. **Target Directory:** `src/invoice-extractor` per user requirement (not root-level)
4. **Quality Tier:** Production (not prototype) - requires full testing and validation
5. **CLI Design:** Single `extract` command with batch and watch mode options

### Agent Assignments

- **@python-developer:** Core Python implementation, dataclasses, parsers, utilities
- **@llm-specialist:** LLM integration, prompt engineering, fallback logic
- **@ai-prompt-specialist:** Vendor-specific extraction prompts
- **@test-generator:** Comprehensive unit and integration tests
- **@code-reviewer:** Code quality, linting, type checking
- **@code-documenter:** Documentation, README, inline docs

### Dependencies

```txt
# Core
pydantic>=2.0
google-cloud-aiplatform>=1.38
google-genai>=0.3.0
openai>=1.0

# Image Processing
pillow>=10.0
pdf2image>=1.16

# Data Output
pyarrow>=15.0
pandas>=2.0

# Configuration
python-dotenv>=1.0
pyyaml>=6.0

# CLI
click>=8.0

# Development
pytest>=7.0
pytest-cov>=4.0
mypy>=1.0
ruff>=0.1.0
black>=23.0
```

### Sample Invoices Available

- data/input/ubereats_INV-UE-19561B_20260123.tiff
- data/input/doordash_INV-DD-2F6981_20260111.tiff
- data/input/grubhub_INV-GH-3633BC_20260122.tiff
- data/input/ifood_INV-IF-E14A54_20260112.tiff
- data/input/rappi_INV-RP-8CC094_20260119.tiff

---

*PROMPT crafted by prompt-crafter agent for dev-loop-executor*
*Ready for execution: `/dev tasks/PROMPT_INVOICE_EXTRACTOR.md`*
